# Extract url from a web shop

A stand-alone web-spider which crawls a list urls obtained from a web site where the web site has multiple pags.
The results are parsed in an output csv file.

## Installation

The webspider is build using Scrapy, a Python based web-crawling framework. 

Run
```
$ pip install Scrapy
```

if you don't have pip, install it, see the instruction here:

```
https://pypi.python.org/pypi/setuptools
```


##Usage

###Clone the repository

```
git clone https://github.com/roencosah/products.git

```

Then,

###Change folder

```
$ cd /productos
```

###Run
```
$ scrapy crawl productos

```

###See the job in
```
/pro.txt
```
